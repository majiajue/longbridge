"""
æ–°é—»å’Œèˆ†æƒ…åˆ†æå™¨ - ä½¿ç”¨ Tavily æœç´¢å¼•æ“
"""
from typing import Dict, List, Optional
import logging
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)

try:
    from tavily import TavilyClient
    HAS_TAVILY = True
except ImportError:
    HAS_TAVILY = False
    TavilyClient = None


class NewsAnalyzer:
    """æ–°é—»å’Œèˆ†æƒ…åˆ†æå™¨"""
    
    def __init__(self, api_key: str):
        if not HAS_TAVILY:
            raise ImportError("éœ€è¦å®‰è£… tavily-python: pip install tavily-python")
        
        if not api_key:
            raise ValueError("å¿…é¡»æä¾› Tavily API Key")
        
        self.client = TavilyClient(api_key)
        logger.info("âœ… Tavily æœç´¢å¼•æ“å·²åˆå§‹åŒ–")
    
    def search_stock_news(
        self,
        symbol: str,
        company_name: Optional[str] = None,
        days: int = 7
    ) -> Dict:
        """
        æœç´¢è‚¡ç¥¨ç›¸å…³æ–°é—»
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            company_name: å…¬å¸åç§°ï¼ˆå¯é€‰ï¼‰
            days: æœç´¢æœ€è¿‘å‡ å¤©çš„æ–°é—»
        
        Returns:
            {
                "news_count": 5,
                "sentiment_score": 0.7,  # -1åˆ°1ï¼Œæ­£é¢/è´Ÿé¢
                "sentiment_label": "POSITIVE/NEUTRAL/NEGATIVE",
                "key_topics": ["è´¢æŠ¥", "æ–°äº§å“", ...],
                "news_items": [
                    {
                        "title": "æ ‡é¢˜",
                        "url": "é“¾æ¥",
                        "published_date": "2024-01-01",
                        "content": "æ‘˜è¦",
                        "score": 0.95
                    }
                ],
                "summary": "æ–°é—»æ€»ç»“",
                "impact_score": 8.5  # 0-10ï¼Œæ–°é—»å¯¹è‚¡ä»·çš„å½±å“ç¨‹åº¦
            }
        """
        try:
            # æ„å»ºæœç´¢æŸ¥è¯¢
            query = self._build_search_query(symbol, company_name)
            
            logger.info(f"ğŸ” æœç´¢æ–°é—»: {query}")
            
            # è°ƒç”¨Tavilyæœç´¢
            response = self.client.search(
                query=query,
                search_depth="advanced",  # æ·±åº¦æœç´¢
                max_results=10,
                include_domains=[
                    "finance.yahoo.com",
                    "seekingalpha.com", 
                    "marketwatch.com",
                    "bloomberg.com",
                    "reuters.com",
                    "cnbc.com",
                    "investing.com"
                ],
                days=days  # æœ€è¿‘Nå¤©
            )
            
            # è§£ææœç´¢ç»“æœ
            analysis = self._analyze_search_results(response, symbol)
            
            logger.info(
                f"âœ… æ–°é—»åˆ†æ: {symbol} - "
                f"{analysis['news_count']}æ¡æ–°é—», "
                f"æƒ…ç»ª:{analysis['sentiment_label']}, "
                f"å½±å“åº¦:{analysis['impact_score']:.1f}"
            )
            
            return analysis
            
        except Exception as e:
            logger.error(f"âŒ æ–°é—»æœç´¢å¤±è´¥: {symbol} - {e}")
            return {
                "news_count": 0,
                "sentiment_score": 0,
                "sentiment_label": "NEUTRAL",
                "key_topics": [],
                "news_items": [],
                "summary": f"æœç´¢å¤±è´¥: {str(e)}",
                "impact_score": 0,
                "error": str(e)
            }
    
    def _build_search_query(self, symbol: str, company_name: Optional[str]) -> str:
        """æ„å»ºæœç´¢æŸ¥è¯¢"""
        # æ¸…ç†è‚¡ç¥¨ä»£ç ï¼ˆå»é™¤.US/.HKç­‰åç¼€ç”¨äºæœç´¢ï¼‰
        clean_symbol = symbol.split('.')[0]
        
        if company_name:
            # å¦‚æœæœ‰å…¬å¸åç§°ï¼Œä¼˜å…ˆä½¿ç”¨
            query = f"{company_name} stock {clean_symbol} news earnings"
        else:
            # åªç”¨è‚¡ç¥¨ä»£ç 
            query = f"{clean_symbol} stock news price movement"
        
        return query
    
    def _analyze_search_results(self, response: Dict, symbol: str) -> Dict:
        """åˆ†ææœç´¢ç»“æœ"""
        results = response.get('results', [])
        
        if not results:
            return {
                "news_count": 0,
                "sentiment_score": 0,
                "sentiment_label": "NEUTRAL",
                "key_topics": [],
                "news_items": [],
                "summary": "æœªæ‰¾åˆ°ç›¸å…³æ–°é—»",
                "impact_score": 0
            }
        
        # æå–æ–°é—»é¡¹
        news_items = []
        for item in results[:10]:  # æœ€å¤š10æ¡
            news_items.append({
                "title": item.get('title', ''),
                "url": item.get('url', ''),
                "content": item.get('content', '')[:500],  # æ‘˜è¦é™åˆ¶500å­—
                "score": item.get('score', 0)
            })
        
        # åˆ†ææƒ…ç»ª
        sentiment_analysis = self._analyze_sentiment(news_items)
        
        # æå–å…³é”®ä¸»é¢˜
        key_topics = self._extract_topics(news_items)
        
        # ç”Ÿæˆæ€»ç»“
        summary = self._generate_summary(news_items, sentiment_analysis)
        
        # è®¡ç®—å½±å“åˆ†æ•°ï¼ˆ0-10ï¼‰
        impact_score = self._calculate_impact_score(
            news_count=len(news_items),
            sentiment_score=sentiment_analysis['score'],
            avg_relevance=sum(n['score'] for n in news_items) / len(news_items) if news_items else 0
        )
        
        return {
            "news_count": len(news_items),
            "sentiment_score": sentiment_analysis['score'],
            "sentiment_label": sentiment_analysis['label'],
            "key_topics": key_topics,
            "news_items": news_items,
            "summary": summary,
            "impact_score": impact_score
        }
    
    def _analyze_sentiment(self, news_items: List[Dict]) -> Dict:
        """
        åˆ†ææ–°é—»æƒ…ç»ª
        
        é€šè¿‡å…³é”®è¯æ£€æµ‹æ­£é¢/è´Ÿé¢æƒ…ç»ª
        """
        positive_keywords = [
            "surge", "jump", "rally", "gain", "rise", "beat", "exceed", 
            "strong", "growth", "profit", "bullish", "upgrade", "buy",
            "record", "high", "outperform", "positive", "optimistic",
            "breakthrough", "success", "winner"
        ]
        
        negative_keywords = [
            "plunge", "drop", "fall", "loss", "decline", "miss", "weak",
            "bearish", "downgrade", "sell", "concern", "risk", "problem",
            "low", "underperform", "negative", "pessimistic", "crisis",
            "failure", "warning", "cut", "reduce"
        ]
        
        positive_count = 0
        negative_count = 0
        total_words = 0
        
        for item in news_items:
            text = (item.get('title', '') + ' ' + item.get('content', '')).lower()
            
            # è®¡æ•°æ­£é¢è¯
            for keyword in positive_keywords:
                positive_count += text.count(keyword)
            
            # è®¡æ•°è´Ÿé¢è¯
            for keyword in negative_keywords:
                negative_count += text.count(keyword)
            
            total_words += len(text.split())
        
        # è®¡ç®—æƒ…ç»ªåˆ†æ•°ï¼ˆ-1åˆ°1ï¼‰
        if positive_count + negative_count == 0:
            sentiment_score = 0
        else:
            sentiment_score = (positive_count - negative_count) / (positive_count + negative_count)
        
        # åˆ†ç±»
        if sentiment_score > 0.2:
            label = "POSITIVE"
        elif sentiment_score < -0.2:
            label = "NEGATIVE"
        else:
            label = "NEUTRAL"
        
        return {
            "score": sentiment_score,
            "label": label,
            "positive_count": positive_count,
            "negative_count": negative_count
        }
    
    def _extract_topics(self, news_items: List[Dict]) -> List[str]:
        """æå–å…³é”®ä¸»é¢˜"""
        topics = set()
        
        # å…³é”®ä¸»é¢˜è¯
        topic_keywords = {
            "è´¢æŠ¥": ["earnings", "report", "revenue", "profit", "eps"],
            "å¹¶è´­": ["merger", "acquisition", "deal", "buyout"],
            "æ–°äº§å“": ["product", "launch", "release", "innovation"],
            "ç›‘ç®¡": ["regulatory", "sec", "fda", "approval"],
            "è¯‰è®¼": ["lawsuit", "legal", "court", "settlement"],
            "åˆ†æå¸ˆ": ["analyst", "rating", "upgrade", "downgrade"],
            "é«˜ç®¡": ["ceo", "executive", "management", "resignation"],
            "å¸‚åœº": ["market", "sector", "industry", "competition"]
        }
        
        for item in news_items:
            text = (item.get('title', '') + ' ' + item.get('content', '')).lower()
            
            for topic_name, keywords in topic_keywords.items():
                if any(keyword in text for keyword in keywords):
                    topics.add(topic_name)
        
        return list(topics)[:5]  # æœ€å¤š5ä¸ªä¸»é¢˜
    
    def _generate_summary(self, news_items: List[Dict], sentiment: Dict) -> str:
        """ç”Ÿæˆæ–°é—»æ€»ç»“"""
        if not news_items:
            return "æ— ç›¸å…³æ–°é—»"
        
        news_count = len(news_items)
        sentiment_label = sentiment['label']
        sentiment_desc = {
            "POSITIVE": "æ­£é¢",
            "NEGATIVE": "è´Ÿé¢",
            "NEUTRAL": "ä¸­æ€§"
        }[sentiment_label]
        
        # å–æœ€ç›¸å…³çš„3æ¡æ–°é—»æ ‡é¢˜
        top_titles = [item['title'] for item in news_items[:3]]
        
        summary = f"å‘ç°{news_count}æ¡ç›¸å…³æ–°é—»ï¼Œæ•´ä½“æƒ…ç»ª{sentiment_desc}ã€‚"
        if top_titles:
            summary += f" ä¸»è¦å†…å®¹ï¼š{'; '.join(top_titles[:2])}"
        
        return summary
    
    def _calculate_impact_score(
        self,
        news_count: int,
        sentiment_score: float,
        avg_relevance: float
    ) -> float:
        """
        è®¡ç®—æ–°é—»å½±å“åˆ†æ•°ï¼ˆ0-10ï¼‰
        
        ç»¼åˆè€ƒè™‘ï¼š
        - æ–°é—»æ•°é‡
        - æƒ…ç»ªå¼ºåº¦
        - ç›¸å…³æ€§
        """
        # æ–°é—»æ•°é‡å› å­ï¼ˆ0-3åˆ†ï¼‰
        if news_count >= 10:
            count_factor = 3.0
        elif news_count >= 5:
            count_factor = 2.0
        elif news_count >= 2:
            count_factor = 1.0
        else:
            count_factor = 0.5
        
        # æƒ…ç»ªå› å­ï¼ˆ0-4åˆ†ï¼‰
        sentiment_factor = abs(sentiment_score) * 4
        
        # ç›¸å…³æ€§å› å­ï¼ˆ0-3åˆ†ï¼‰
        relevance_factor = avg_relevance * 3
        
        impact = count_factor + sentiment_factor + relevance_factor
        
        return min(10, max(0, impact))


def get_news_analyzer(api_key: str) -> Optional[NewsAnalyzer]:
    """è·å–æ–°é—»åˆ†æå™¨å®ä¾‹"""
    try:
        return NewsAnalyzer(api_key)
    except Exception as e:
        logger.error(f"âŒ æ— æ³•åˆå§‹åŒ–æ–°é—»åˆ†æå™¨: {e}")
        return None






